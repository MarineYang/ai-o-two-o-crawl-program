# 프로젝트 개요

이 프로그램은 네이버 지도를 크롤링하여 특정 장소의 메타데이터를 수집하고, 이를 데이터베이스에 저장하는 기능을 제공합니다. 크롤러는 장소의 기본 정보, 리뷰, 블로그 게시물, 사진 등을 수집합니다.

## 프로그램 구조

- **main.py**: 프로그램의 진입점으로, 크롤러를 실행하고 데이터를 수집하여 데이터베이스에 저장합니다.
- **db_manager.py**: 데이터베이스 연결 및 관리, 테이블 생성, 데이터 삽입 등의 기능을 제공합니다.
- **DTOs.py**: 데이터 전송 객체(Data Transfer Objects)를 정의하여 데이터의 구조를 명확히 합니다.
- **models.py**: SQLAlchemy를 사용하여 데이터베이스 테이블 모델을 정의합니다.
- **configs/**: 설정 파일을 포함하여 데이터베이스 연결 정보 등을 관리합니다.

## 데이터베이스 저장 방식

- **SQLAlchemy**: ORM(Object-Relational Mapping)을 사용하여 데이터베이스와 상호작용합니다.
- **AsyncIO**: 비동기 데이터베이스 작업을 수행하기 위해 `aiomysql`과 `AsyncSession`을 사용합니다.
- **데이터 모델**: `Place`, `PlaceHours`, `Review`, `Blog`, `BlogImage`, `PlacePhoto` 등의 테이블로 구성되어 있으며, 각 테이블은 관련 데이터를 저장합니다.

## 데이터베이스 롤백 처리

- **트랜잭션 관리**: 모든 데이터베이스 작업은 트랜잭션으로 관리되며, 오류 발생 시 자동으로 롤백됩니다.
- **세션 관리**: `async with session()` 컨텍스트 매니저를 사용하여 세션을 관리합니다.
- **예외 처리**: 데이터 저장 중 오류가 발생하면 해당 트랜잭션의 모든 변경사항이 롤백되어 데이터 일관성이 유지됩니다.

### 롤백이 발생하는 경우
- 데이터베이스 연결 오류
- 데이터 무결성 위반
- 크롤링 중 예외 발생
- 기타 예외 상황 발생

모든 데이터베이스 작업은 트랜잭션으로 처리되어, 작업 중 오류가 발생하면 이전 상태로 안전하게 복원됩니다.

## 설치 및 실행 방법

1. **의존성 설치**:
   ```bash
   pip install -r requirements.txt
   ```

2. **데이터베이스 설정**:
   `configs/config.toml` 파일을 수정하여 데이터베이스 연결 정보를 설정합니다.

3. **프로그램 실행**:
   ```bash
   run_crawler.bat "가게 이름"
   ```

   # 예시
   ```bash
   run_crawler.bat "선돌막국수"
   ```

   가게 이름을 인자로 제공하여 실행합니다.


